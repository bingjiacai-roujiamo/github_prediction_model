{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a89fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os\n",
    "import missingno as msno #缺失值可视化 https://github.com/ResidentMario/missingno\n",
    "\n",
    "# 设置随机种子，确保结果可重复\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a507733",
   "metadata": {},
   "source": [
    "# 1.数据查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"D:/vscode_work/mechine learning/IHC_data.csv\")\n",
    "\n",
    "#查看分类变量的频数分布\n",
    "categorical_features = ['outcome', 'sex', 'nation', 'infection', 'infected_coition', 'biopsy',\n",
    "                        'syringe', 'disease', 'previous_treatment', 'treatment_history',\n",
    "                        'treatment', 'nuc', 'IFN', 'A', 'FL', 'FL_grading', 'A_24w', 'FL_24w',\n",
    "                        'FL_grade_24w']\n",
    "print(\"\\n分类变量的频数分布:\")\n",
    "for var in categorical_features:\n",
    "    print(f\"\\n{var} 的频数分布:\")\n",
    "    print(data[var].value_counts(dropna=False))\n",
    "\n",
    "#绘制连续变量箱线图\n",
    "# continuous_variables = [col for col in data.columns if col not in categorical_features]\n",
    "# print(len(continuous_variables)) #连续变量的个数\n",
    "# plt.figure(figsize=(110, 200))\n",
    "# for i, var in enumerate(continuous_variables, 1):\n",
    "#     plt.subplot(11, 10, i)\n",
    "#     sns.boxplot(y=data[var].dropna())\n",
    "#     plt.title(var)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('D:/vscode_work/mechine learning/连续变量箱线图.png', dpi=300, bbox_inches='tight') #和上面的plt.figure(figsize=(18, 90))一起运行\n",
    "\n",
    "print(\"\\n查看数据缺失情况\")\n",
    "missing_percentage = (data.isnull().sum() / len(data))*100\n",
    "print(\"/特征缺失百分比\\n\", missing_percentage.to_string)  \n",
    "\n",
    "# 缺失值可视化\n",
    "msno.matrix(data, labels=True, label_rotation=90)  \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(data.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('heaatmap', fontsize=16)\n",
    "plt.show() #显示缺失值热力图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d44d8c",
   "metadata": {},
   "source": [
    "# 2.处理异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cfcd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义分类变量和连续变量\n",
    "categorical_features = ['outcome', 'sex', 'nation', 'infection', 'infected_coition', 'biopsy',\n",
    "                        'syringe', 'disease', 'previous_treatment', 'treatment_history',\n",
    "                        'treatment', 'nuc', 'IFN', 'A', 'FL', 'FL_grading', 'A_24w', 'FL_24w',\n",
    "                        'FL_grade_24w']\n",
    "continuous_variables = [col for col in data.columns if col not in categorical_features]\n",
    "\n",
    "#异常值情况\n",
    "for var in continuous_variables:\n",
    "    q1 = data[var].quantile(0.25)\n",
    "    q3 = data[var].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    outliers = data[(data[var] < lower_bound) | (data[var] > upper_bound)]\n",
    "    \n",
    "    print(f\"\\n{var} 的异常值数：{outliers.shape[0]}\")  # 打印异常值个数\n",
    "    if not outliers.empty:\n",
    "        print(outliers[[var]])  # 只展示当前变量的异常值列，防止输出太多\n",
    "\n",
    "    # 把异常值变成缺失值\n",
    "    data.loc[outliers.index, var] = np.nan\n",
    "\n",
    "#删除异常值后的数据摘要\n",
    "print(\"\\n删除异常值后的数据摘要：\")\n",
    "print(data.describe())\n",
    "print(data.info())  # 查看数据结构\n",
    "\n",
    "# 删除异常值后的数据缺失情况\n",
    "print(\"\\n删除异常值后的变量缺失情况：\")\n",
    "missing_percentage = (data.isnull().sum() / len(data)) * 100\n",
    "print(missing_percentage.to_string()) #输出缺失值百分比\n",
    "\n",
    "# 删除缺失超过60%的列\n",
    "columns_to_drop = missing_percentage[missing_percentage > 30].index\n",
    "print(f\"\\n将要删除的列：{list(columns_to_drop)}\")\n",
    "\n",
    "data = data.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"\\n删除后剩余的列数：{data.shape[1]}\")\n",
    "data.to_csv(\"D:/vscode_work/mechine learning/IHC.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c8df8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 异常值数量 = 0\n",
      "height: 异常值数量 = 0\n",
      "weight: 异常值数量 = 4\n",
      "SBP: 异常值数量 = 33\n",
      "DBP: 异常值数量 = 20\n",
      "medical_history: 异常值数量 = 14\n",
      "D: 异常值数量 = 119\n",
      "HBsAg: 异常值数量 = 8\n",
      "HBsAb: 异常值数量 = 87\n",
      "HBeAg: 异常值数量 = 7\n",
      "HBeAb: 异常值数量 = 138\n",
      "HBcAb: 异常值数量 = 152\n",
      "ALT: 异常值数量 = 0\n",
      "AST: 异常值数量 = 23\n",
      "TBIL: 异常值数量 = 31\n",
      "TP: 异常值数量 = 12\n",
      "ALB: 异常值数量 = 21\n",
      "BUN: 异常值数量 = 12\n",
      "Cr: 异常值数量 = 6\n",
      "GLU: 异常值数量 = 21\n",
      "DBIL: 异常值数量 = 30\n",
      "HB: 异常值数量 = 21\n",
      "WBC: 异常值数量 = 18\n",
      "ANC: 异常值数量 = 21\n",
      "PLT: 异常值数量 = 13\n",
      "ANC_per: 异常值数量 = 43\n",
      "T3: 异常值数量 = 2\n",
      "T4: 异常值数量 = 0\n",
      "FT3: 异常值数量 = 30\n",
      "FT4: 异常值数量 = 47\n",
      "TSH: 异常值数量 = 17\n",
      "TPOAb: 异常值数量 = 88\n",
      "TGAb: 异常值数量 = 74\n",
      "TRAb: 异常值数量 = 18\n",
      "AFP: 异常值数量 = 32\n",
      "E: 异常值数量 = 9\n",
      "CAP: 异常值数量 = 7\n",
      "D_12w: 异常值数量 = 94\n",
      "HBsAg_12w: 异常值数量 = 69\n",
      "HBsAb_12w: 异常值数量 = 85\n",
      "HBeAg_12w: 异常值数量 = 14\n",
      "HBeAb_12w: 异常值数量 = 91\n",
      "HBcAb_12w: 异常值数量 = 102\n",
      "ALT_12w: 异常值数量 = 37\n",
      "AST_12w: 异常值数量 = 32\n",
      "TBIL_12w: 异常值数量 = 23\n",
      "TP_12w: 异常值数量 = 10\n",
      "ALB_12w: 异常值数量 = 11\n",
      "BUN_12w: 异常值数量 = 4\n",
      "Cr_12w: 异常值数量 = 2\n",
      "GLU_12w: 异常值数量 = 18\n",
      "DBIL_12w: 异常值数量 = 20\n",
      "HB_12w: 异常值数量 = 4\n",
      "WBC_12w: 异常值数量 = 35\n",
      "ANC_12w: 异常值数量 = 33\n",
      "PLT_12w: 异常值数量 = 22\n",
      "ANC_per_12w: 异常值数量 = 39\n",
      "D_24w: 异常值数量 = 71\n",
      "HBsAg_24w: 异常值数量 = 109\n",
      "HBsAb_24w: 异常值数量 = 107\n",
      "HBeAg_24w: 异常值数量 = 21\n",
      "HBeAb_24w: 异常值数量 = 106\n",
      "HBcAb_24w: 异常值数量 = 118\n",
      "ALT_24w: 异常值数量 = 48\n",
      "AST_24w: 异常值数量 = 41\n",
      "TBIL_24w: 异常值数量 = 24\n",
      "TP_24w: 异常值数量 = 8\n",
      "ALB_24w: 异常值数量 = 11\n",
      "BUN_24w: 异常值数量 = 7\n",
      "Cr_24w: 异常值数量 = 1\n",
      "GLU_24w: 异常值数量 = 14\n",
      "DBIL_24w: 异常值数量 = 22\n",
      "HB_24w: 异常值数量 = 10\n",
      "WBC_24w: 异常值数量 = 28\n",
      "ANC_24w: 异常值数量 = 32\n",
      "PLT_24w: 异常值数量 = 18\n",
      "ANC_per_24w: 异常值数量 = 45\n",
      "T3_24w: 异常值数量 = 1\n",
      "T4_24w: 异常值数量 = 1\n",
      "FT3_24w: 异常值数量 = 36\n",
      "FT4_24w: 异常值数量 = 45\n",
      "TSH_24w: 异常值数量 = 26\n",
      "TPOAb_24w: 异常值数量 = 60\n",
      "TGAb_24w: 异常值数量 = 53\n",
      "TRAb_24w: 异常值数量 = 8\n",
      "AFP_24w: 异常值数量 = 28\n",
      "E_24w: 异常值数量 = 6\n",
      "CAP_24w: 异常值数量 = 4\n",
      "D_36w: 异常值数量 = 37\n",
      "HBsAg_36w: 异常值数量 = 98\n",
      "HBsAb_36w: 异常值数量 = 90\n",
      "HBeAg_36w: 异常值数量 = 12\n",
      "HBeAb_36w: 异常值数量 = 83\n",
      "HBcAb_36w: 异常值数量 = 94\n",
      "ALT_36w: 异常值数量 = 35\n",
      "AST_36w: 异常值数量 = 36\n",
      "TBIL_36w: 异常值数量 = 15\n",
      "TP_36w: 异常值数量 = 14\n",
      "ALB_36w: 异常值数量 = 7\n",
      "BUN_36w: 异常值数量 = 7\n",
      "Cr_36w: 异常值数量 = 1\n",
      "GLU_36w: 异常值数量 = 10\n",
      "DBIL_36w: 异常值数量 = 13\n",
      "HB_36w: 异常值数量 = 9\n",
      "WBC_36w: 异常值数量 = 30\n",
      "ANC_36w: 异常值数量 = 28\n",
      "PLT_36w: 异常值数量 = 14\n",
      "ANC_per_36w: 异常值数量 = 43\n",
      "\n",
      "删除缺失率超过30%的列: ['SBP', 'DBP', 'infected_coition', 'previous_treatment', 'treatment_history', 'nuc', 'GLU', 'T3', 'T4', 'FT3', 'FT4', 'TSH', 'TPOAb', 'TGAb', 'TRAb', 'A', 'E', 'CAP', 'FL', 'FL_grading', 'BUN_12w', 'Cr_12w', 'GLU_12w', 'BUN_24w', 'Cr_24w', 'GLU_24w', 'T3_24w', 'T4_24w', 'FT3_24w', 'FT4_24w', 'TSH_24w', 'TPOAb_24w', 'TGAb_24w', 'TRAb_24w', 'AFP_24w', 'A_24w', 'E_24w', 'CAP_24w', 'FL_24w', 'FL_grade_24w', 'D_36w', 'HBsAb_36w', 'HBeAg_36w', 'HBeAb_36w', 'HBcAb_36w', 'ALT_36w', 'AST_36w', 'TBIL_36w', 'TP_36w', 'ALB_36w', 'BUN_36w', 'Cr_36w', 'GLU_36w', 'DBIL_36w', 'HB_36w', 'WBC_36w', 'ANC_36w', 'PLT_36w', 'ANC_per_36w']\n",
      "\n",
      "处理后数据摘要:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777 entries, 0 to 776\n",
      "Data columns (total 69 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   outcome          777 non-null    int64  \n",
      " 1   sex              773 non-null    float64\n",
      " 2   age              771 non-null    float64\n",
      " 3   nation           773 non-null    float64\n",
      " 4   height           625 non-null    float64\n",
      " 5   weight           624 non-null    float64\n",
      " 6   medical_history  610 non-null    float64\n",
      " 7   infection        757 non-null    float64\n",
      " 8   infected_person  726 non-null    float64\n",
      " 9   biopsy           770 non-null    float64\n",
      " 10  syringe          764 non-null    float64\n",
      " 11  disease          765 non-null    float64\n",
      " 12  treatment        777 non-null    int64  \n",
      " 13  IFN              776 non-null    float64\n",
      " 14  D                777 non-null    float64\n",
      " 15  HBsAg            777 non-null    float64\n",
      " 16  HBsAb            777 non-null    float64\n",
      " 17  HBeAg            777 non-null    float64\n",
      " 18  HBeAb            777 non-null    float64\n",
      " 19  HBcAb            777 non-null    float64\n",
      " 20  ALT              777 non-null    float64\n",
      " 21  AST              772 non-null    float64\n",
      " 22  TBIL             767 non-null    float64\n",
      " 23  TP               752 non-null    float64\n",
      " 24  ALB              759 non-null    float64\n",
      " 25  BUN              529 non-null    float64\n",
      " 26  Cr               555 non-null    float64\n",
      " 27  DBIL             749 non-null    float64\n",
      " 28  HB               761 non-null    float64\n",
      " 29  WBC              761 non-null    float64\n",
      " 30  ANC              734 non-null    float64\n",
      " 31  PLT              747 non-null    float64\n",
      " 32  ANC_per          722 non-null    float64\n",
      " 33  AFP              532 non-null    float64\n",
      " 34  D_12w            508 non-null    float64\n",
      " 35  HBsAg_12w        609 non-null    float64\n",
      " 36  HBsAb_12w        567 non-null    float64\n",
      " 37  HBeAg_12w        581 non-null    float64\n",
      " 38  HBeAb_12w        560 non-null    float64\n",
      " 39  HBcAb_12w        560 non-null    float64\n",
      " 40  ALT_12w          601 non-null    float64\n",
      " 41  AST_12w          598 non-null    float64\n",
      " 42  TBIL_12w         593 non-null    float64\n",
      " 43  TP_12w           578 non-null    float64\n",
      " 44  ALB_12w          584 non-null    float64\n",
      " 45  DBIL_12w         585 non-null    float64\n",
      " 46  HB_12w           601 non-null    float64\n",
      " 47  WBC_12w          603 non-null    float64\n",
      " 48  ANC_12w          575 non-null    float64\n",
      " 49  PLT_12w          591 non-null    float64\n",
      " 50  ANC_per_12w      571 non-null    float64\n",
      " 51  D_24w            568 non-null    float64\n",
      " 52  HBsAg_24w        670 non-null    float64\n",
      " 53  HBsAb_24w        615 non-null    float64\n",
      " 54  HBeAg_24w        636 non-null    float64\n",
      " 55  HBeAb_24w        616 non-null    float64\n",
      " 56  HBcAb_24w        616 non-null    float64\n",
      " 57  ALT_24w          662 non-null    float64\n",
      " 58  AST_24w          660 non-null    float64\n",
      " 59  TBIL_24w         655 non-null    float64\n",
      " 60  TP_24w           644 non-null    float64\n",
      " 61  ALB_24w          651 non-null    float64\n",
      " 62  DBIL_24w         647 non-null    float64\n",
      " 63  HB_24w           648 non-null    float64\n",
      " 64  WBC_24w          650 non-null    float64\n",
      " 65  ANC_24w          630 non-null    float64\n",
      " 66  PLT_24w          645 non-null    float64\n",
      " 67  ANC_per_24w      624 non-null    float64\n",
      " 68  HBsAg_36w        526 non-null    float64\n",
      "dtypes: float64(67), int64(2)\n",
      "memory usage: 419.0 KB\n",
      "None\n",
      "\n",
      "数据已保存至: D:/vscode_work/mechine learning/IHC_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "data = pd.read_csv(\"D:/vscode_work/mechine learning/IHC_data.csv\")\n",
    "\n",
    "# --- 步骤1：定义分类变量和连续变量 ---\n",
    "# 分类变量列表（根据实际列名调整）\n",
    "categorical_features = [\n",
    "    'outcome', 'sex', 'nation', 'infection', 'infected_coition', 'infected_person', 'biopsy',\n",
    "    'syringe', 'disease', 'previous_treatment', 'treatment_history',\n",
    "    'treatment', 'nuc', 'IFN', 'A', 'FL', 'FL_grading', 'A_24w', 'FL_24w',\n",
    "    'FL_grade_24w'\n",
    "]\n",
    "\n",
    "# 连续变量 = 所有列 - 分类变量\n",
    "continuous_variables = [col for col in data.columns if col not in categorical_features]\n",
    "\n",
    "# --- 步骤2：使用Tukey方法检测和处理异常值 ---\n",
    "for var in continuous_variables:\n",
    "    # 跳过非数值型列（确保安全）\n",
    "    if var not in data.select_dtypes(include=[np.number]).columns:\n",
    "        continue\n",
    "    \n",
    "    # 计算四分位数和IQR\n",
    "    q1 = data[var].quantile(0.25)\n",
    "    q3 = data[var].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    # 计算上下界（Tukey方法默认用1.5倍IQR）\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    # 检测异常值（直接标记为布尔索引）\n",
    "    is_outlier = (data[var] < lower_bound) | (data[var] > upper_bound)\n",
    "    num_outliers = is_outlier.sum()  # 统计异常值数量\n",
    "    \n",
    "    # 打印结果（仅保留异常值数量，避免输出过多内容）\n",
    "    print(f\"{var}: 异常值数量 = {num_outliers}\")\n",
    "    \n",
    "    # 将异常值替换为NaN（直接操作原DataFrame）\n",
    "    # data.loc[is_outlier, var] = np.nan\n",
    "    data[var] = data[var].clip(lower=lower_bound, upper=upper_bound)#  将异常值替换为边界值\n",
    "\n",
    "data.to_csv(\"D:/vscode_work/mechine learning/IHC_Tukey.csv\", index=False)\n",
    "\n",
    "# --- 步骤3：处理缺失值（删除高缺失率列） ---\n",
    "# 计算每列的缺失率\n",
    "missing_percentage = (data.isnull().sum() / len(data)) * 100\n",
    "\n",
    "# 标记缺失率超过30%的列\n",
    "columns_to_drop = missing_percentage[missing_percentage > 35].index.tolist()\n",
    "\n",
    "# 删除高缺失率列（如果存在）\n",
    "if columns_to_drop:\n",
    "    print(f\"\\n删除缺失率超过30%的列: {columns_to_drop}\")\n",
    "    data = data.drop(columns=columns_to_drop)\n",
    "else:\n",
    "    print(\"\\n没有列需要删除\")\n",
    "\n",
    "# --- 步骤4：保存处理后的数据 ---\n",
    "# 输出最终数据信息\n",
    "print(\"\\n处理后数据摘要:\")\n",
    "print(data.info())\n",
    "\n",
    "# 保存到新文件（避免覆盖原始数据）\n",
    "output_path = \"D:/vscode_work/mechine learning/IHC_cleaned.csv\"\n",
    "data.to_csv(output_path, index=False)\n",
    "print(f\"\\n数据已保存至: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5659a043",
   "metadata": {},
   "source": [
    "# 3.正态性检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e31457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "data = pd.read_csv(\"D:/vscode_work/mechine learning/IHC.csv\")\n",
    "categorical_features = ['outcome', 'sex', 'nation', 'infection', 'infected_person', 'biopsy',\n",
    "                        'syringe', 'disease', 'treatment', 'IFN'] #重新 定义分类变量\n",
    "continuous_variables = [col for col in data.columns if col not in categorical_features]\n",
    "results = []\n",
    "for col in continuous_variables:\n",
    "    colum_data = data[col].dropna()\n",
    "    # 执行多种检验\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(colum_data)\n",
    "    dagostino_stat, dagostino_p = stats.normaltest(colum_data)\n",
    "    \n",
    "    results.append({\n",
    "        \"Column\": col,\n",
    "        \"Shapiro-Wilk p\": round(shapiro_p, 4),\n",
    "        \"D'Agostino p\": round(dagostino_p, 4),\n",
    "        \"Normality (Shapiro)\": \"Yes\" if shapiro_p > 0.05 else \"No\",\n",
    "        \"Normality (D'Agostino)\": \"Yes\" if dagostino_p > 0.05 else \"No\"\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d91f0",
   "metadata": {},
   "source": [
    "# 4.缺失值插补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "694e12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_csv(\"D:/vscode_work/mechine learning/IHC_cleaned.csv\")\n",
    "# 连续变量插补\n",
    "categorical_features = ['outcome', 'sex', 'nation', 'infection', 'infected_person',\n",
    "                        'treatment', 'IFN'] #重新 定义分类变量\n",
    "continuous_variables = [col for col in data.columns if col not in categorical_features] #重新 定义数值变量\n",
    "\n",
    "continuous_imputer = IterativeImputer(random_state=RANDOM_STATE, max_iter=10, min_value=0, sample_posterior=True)\n",
    "continuous_data_imputed = pd.DataFrame(continuous_imputer.fit_transform(data[continuous_variables]), columns=continuous_variables)\n",
    "\n",
    "# 分类变量插补\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "categorical_data_imputed = pd.DataFrame(categorical_imputer.fit_transform(data[categorical_features]), columns=categorical_features)\n",
    "\n",
    "# 合并\n",
    "completed_data = pd.concat([continuous_data_imputed, categorical_data_imputed], axis=1)\n",
    "\n",
    "# 查看填补后数据的缺失情况\n",
    "completed_data.isnull().sum()\n",
    "\n",
    "# 注意整数变量的填补值也要保留整数\n",
    "integer_columns = ['outcome', 'sex', 'nation', 'height', 'weight', 'infection', 'infected_person', 'treatment', 'IFN', 'HB', 'PLT', \n",
    "                        'HB_12w', 'PLT_12w', 'HB_24w', 'PLT_24w']\n",
    "\n",
    "completed_data[integer_columns] = completed_data[integer_columns].round()\n",
    "\n",
    "# 保存填补后的数据\n",
    "completed_data.to_csv(\"D:/vscode_work/mechine learning/IHC_im.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5075fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_csv(\"D:/vscode_work/mechine learning/IHC_im.csv\")\n",
    "data.isnull().sum()\n",
    "sns.heatmap(data.isna(), cbar=False, cmap='viridis')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
